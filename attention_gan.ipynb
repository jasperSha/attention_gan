{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "attention_gan.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtfTndYJvYVZ"
      },
      "source": [
        "!pip install imageio git+https://github.com/tensorflow/docs XlsxWriter tensorflow_addons &> /dev/null"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PxuB468yOJ1",
        "outputId": "9e003747-c511-4cd9-f393-6dae9651423b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POimF4n2q9J_"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwJIdwZlchUj"
      },
      "source": [
        "# !echo \"deb http://packages.cloud.google.com/apt gcsfuse-bionic main\" > /etc/apt/sources.list.d/gcsfuse.list\n",
        "# !curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
        "# !apt -qq update\n",
        "# !apt -qq install gcsfuse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N-GIBfjdcAv"
      },
      "source": [
        "# !gcloud auth application-default login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzsCiez-dy2P"
      },
      "source": [
        "# !gcloud auth login"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7vuxbkS-X3W"
      },
      "source": [
        "!mkdir historical\n",
        "!mkdir future\n",
        "!gsutil -m cp gs://ganstick_project/historical/*.png historical/\n",
        "!gsutil -m cp gs://ganstick_project/future/*.png future/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EBREkkabyhq"
      },
      "source": [
        "# !gcsfuse --implicit-dirs ganstick_project gcloudbucket"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AlHTSh2YIOYK"
      },
      "source": [
        "import tensorflow as tf\n",
        "import glob\n",
        "import imageio\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import PIL\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow_addons.layers import SpectralNormalization as SpectralNorm\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras_preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.layers import InputSpec, Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "\n",
        "import time\n",
        "\n",
        "from IPython import display\n",
        "import tensorflow_docs.vis.embed as embed\n",
        "import xlsxwriter\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gC-tqekUydXg"
      },
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "np.set_printoptions(suppress=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46u3tiQWtQIM"
      },
      "source": [
        "tickers = [\n",
        "  'aapl',\n",
        "  'mcd',\n",
        "  'pld',\n",
        "  'bac',\n",
        "  'cvx',\n",
        "  'ibm',\n",
        "  'v',\n",
        "  'pg',\n",
        "  'nke',\n",
        "  'abbv',\n",
        "  'mmm',\n",
        "  'rio',\n",
        "  'cci',\n",
        "  'ip',\n",
        "  'gs',\n",
        "  'hon',\n",
        "  'msft',\n",
        "  'amt',\n",
        "  'spg',\n",
        "  'jpm',\n",
        "  'amzn',\n",
        "  'unh',\n",
        "  'wmt',\n",
        "  'jnj',\n",
        "  'vz',\n",
        "  'bhp',\n",
        "  'nee',\n",
        "  'etr',\n",
        "  'xel',\n",
        "  'pfe',\n",
        "  'xom',\n",
        "  'lmt',\n",
        "  'duk',\n",
        "  'googl',\n",
        "  'viac',\n",
        "  'intc',\n",
        "  'ko',\n",
        "  ]\n",
        "future_vols = []\n",
        "hist_vols = []\n",
        "for ticker in tickers:\n",
        "  fname = glob.glob(\"drive/MyDrive/ganstick_project/historical_volatility/%s/%s_hist_vol.csv\"%(ticker, ticker))[0]\n",
        "  df = pd.read_csv(fname)\n",
        "  df['id'] = range(0, len(df))\n",
        "  # super super janky but possibly only way to make image data generator figure it out\n",
        "  df['id'] = df['id'].apply(lambda x: 'historical/%s_'%ticker + str(x) + '.png')\n",
        "\n",
        "  # chop off first 1000 days (4 years) to get rid of most of the all green candle images\n",
        "  df = df.iloc[2500:]\n",
        "  hist_vols.append(df)\n",
        "\n",
        "all_hist_vols = pd.concat([df for df in hist_vols])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNRuWjZ6vgj9",
        "outputId": "00a98d26-07c0-4456-8408-0dcca0040fcb"
      },
      "source": [
        "# 64 fast training for each but may be too slow overall --> use 256\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "def process(image):\n",
        "  image = tf.cast((image-127.5) / 127.5 ,tf.float32)\n",
        "  return image\n",
        "\n",
        "image_gen = ImageDataGenerator(\n",
        "    preprocessing_function=process\n",
        ")\n",
        "\n",
        "# class_mode == raw --> pass in multiple columns to y_col to add\n",
        "hist_gen = image_gen.flow_from_dataframe(\n",
        "    dataframe=all_hist_vols,\n",
        "    directory=None,\n",
        "    x_col='id',\n",
        "    y_col=['avg_vol', 'first_date', 'last_date', 'avg_volume', 'ticker'],\n",
        "    target_size=(56,56),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    class_mode='raw',\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 283820 validated image filenames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bux8PWQdQqsY"
      },
      "source": [
        "def Attention(input_shape, k):\n",
        "  '''\n",
        "  @param int k: proportion by which we subsample the input\n",
        "  '''\n",
        "  channels = input_shape[-1]\n",
        "  x = layers.Input(shape=input_shape[1:])\n",
        "\t\n",
        "  f = layers.Conv2D(channels // k, kernel_size = (1, 1), strides = (1, 1), padding='same', use_bias=True)(x)\n",
        "  f = layers.Reshape((-1, f.shape[-1]))(f)\n",
        "\t\n",
        "  g = layers.Conv2D(channels // k, kernel_size = (1, 1), strides = (1, 1), padding='same', use_bias=True)(x)\n",
        "  g = layers.Reshape((-1, g.shape[-1]))(g)\n",
        "\t\n",
        "  h = layers.Conv2D(channels // 2, kernel_size = (1, 1), strides = (1, 1), padding='same', use_bias=True)(x)\n",
        "  h = layers.Reshape((-1, h.shape[-1]))(h)\n",
        "\t\n",
        "  s = tf.matmul(g, f, transpose_b=True)\n",
        "  s = keras.layers.Softmax()(s)\n",
        "\t\t\n",
        "  o = tf.matmul(s, h)\n",
        "\n",
        "  # first dim is batch size\n",
        "  height, width, channels = input_shape[1:]\n",
        "  o = layers.Reshape((height, width, channels // 2))(o)\n",
        "  o = layers.Conv2D(channels, kernel_size = (1, 1), strides = (1, 1), padding='same', use_bias=True)(o)\n",
        "  o = Scalar()(o)\n",
        "  o = o + x\n",
        "\n",
        "  SA = keras.Model(inputs=x, outputs=o)\n",
        "\t\n",
        "  return SA\n",
        "\n",
        "\n",
        "class Scalar(layers.Layer):\n",
        "  def __init__(self):\n",
        "    super(Scalar, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    self.gamma = tf.Variable(initial_value=tf.zeros(1), trainable=True)\n",
        "    self._trainable_weights=[self.gamma]\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return layers.Rescaling(self.gamma)(inputs)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5xZ8iyqFFtj"
      },
      "source": [
        "def make_generator_model():\n",
        "  # create noise and reshape\n",
        "  input_noise = layers.Input(shape=(100,))\n",
        "  n_nodes = 256 * 7 * 7\n",
        "  noise = layers.Dense(n_nodes)(input_noise)\n",
        "\n",
        "  # not sure if we need activation or not\n",
        "  gen_image = layers.Reshape((7, 7, 256))(noise)\n",
        "  gen_image = layers.BatchNormalization()(gen_image)\n",
        "  gen_image = layers.LeakyReLU()(gen_image)\n",
        "\n",
        "  gen_image = SpectralNorm(layers.Conv2DTranspose(64, (3,3), strides=(2, 2), padding='same', use_bias=False))(gen_image)\n",
        "  gen_image = layers.LeakyReLU()(gen_image)\n",
        "\n",
        "  input_shape = gen_image.shape\n",
        "  gen_image = Attention(input_shape, k=8)(gen_image)\n",
        "\n",
        "  gen_image = layers.BatchNormalization()(gen_image)\n",
        "  gen_image = SpectralNorm(layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', use_bias=False))(gen_image)\n",
        "  gen_image = layers.LeakyReLU()(gen_image)\n",
        "\n",
        "  # self attention\n",
        "  input_shape = gen_image.shape\n",
        "  gen_image = Attention(input_shape, k=4)(gen_image)\n",
        "  \n",
        "  gen_image = layers.BatchNormalization()(gen_image)\n",
        "  gen_image = SpectralNorm(layers.Conv2DTranspose(3, (3, 3), strides=(2, 2), padding='same', use_bias=False, activation=keras.activations.tanh))(gen_image)\n",
        "  \n",
        "  model = keras.Model(inputs=input_noise, outputs=gen_image)\n",
        "\n",
        "  return model\n",
        "\n",
        "def make_discriminator_model():\n",
        "  input_image = layers.Input(shape=(56, 56, 3))\n",
        "\n",
        "  image = SpectralNorm(layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same'))(input_image)\n",
        "  image = layers.LeakyReLU()(image)\n",
        "\n",
        "  # Self-attention\n",
        "  input_shape = image.shape\n",
        "  image = Attention(input_shape, k=4)(image)\n",
        "\n",
        "  image = SpectralNorm(layers.Conv2D(64, (3, 3), strides=(2, 2), padding='same'))(image)\n",
        "  image = layers.LeakyReLU()(image)\n",
        "\n",
        "  # self attention\n",
        "  input_shape = image.shape\n",
        "  image = Attention(input_shape, k=8)(image)\n",
        "\n",
        "  feature = layers.Flatten()(image)\n",
        "\n",
        "  prediction = layers.Dense(1, activation=keras.activations.sigmoid)(feature)\n",
        "  model = keras.Model(inputs=input_image, outputs=prediction)\n",
        "  return model\n",
        "\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERJc-BgYB8Zq"
      },
      "source": [
        "generator.summary()\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2N0jm32hRmCi"
      },
      "source": [
        "\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy()\n",
        "\n",
        "# TTUR (discriminator 4x learning rate of generator)\n",
        "generator_optimizer = tf.keras.optimizers.Adam(0.0001, beta_1=0.0, beta_2=0.9)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(0.0004, beta_1=0.0, beta_2=0.9)\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "  return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "  real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "  fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "  total_loss = real_loss + fake_loss\n",
        "  return total_loss\n",
        "\n",
        "# decode for ticker string\n",
        "def recover_string_from_int(x):\n",
        "  recoveredbytes = x.to_bytes((x.bit_length() + 7) // 8, 'little')\n",
        "  recoveredstring = recoveredbytes.decode('utf-8')\n",
        "  return recoveredstring\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0roSopzRmpZ",
        "outputId": "966229a1-9781-459d-fd61-59ff40d768fe"
      },
      "source": [
        "# this cell for saving directly to gdrive but setting experimental options\n",
        "\n",
        "# for reading from either gdrive or local? or only local not sure\n",
        "local_device_option = tf.train.CheckpointOptions(experimental_io_device=\"/job:localhost\")\n",
        "\n",
        "checkpoint_dir = 'drive/MyDrive/ganstick_project/checkpoints/finalgan/'\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "                  discriminator_optimizer=discriminator_optimizer,\n",
        "                  generator=generator,\n",
        "                  discriminator=discriminator)\n",
        "\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir), options=local_device_option)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7ff6f6aca550>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqPnZmvaljTm"
      },
      "source": [
        "# # this cell for loading/saving checkpoints locally in VM then copying to gdrive\n",
        "\n",
        "# !gsutil cp -r drive/MyDrive/ganstick_project/checkpoints/finalgan/checkpoints .\n",
        "\n",
        "# checkpoint_dir = 'checkpoints'\n",
        "# checkpoint_dir = os.path.join(checkpoint_dir, 'ckpt')\n",
        "\n",
        "# checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
        "#                   discriminator_optimizer=discriminator_optimizer,\n",
        "#                   generator=generator,\n",
        "#                   discriminator=discriminator)\n",
        "\n",
        "# checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "# # saving: \n",
        "# # !gsutil cp -r checkpoints/ drive/MyDrive/ganstick_project/checkpoints/finalgan/\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbTyZxufR31y"
      },
      "source": [
        "# Training process\n",
        "@tf.function\n",
        "def train_step(img_batch):\n",
        "  '''\n",
        "\n",
        "  img_batch.shape = [batch_size, height, width, channels]\n",
        "  img_labels.shape = [batch_size, labels]\n",
        "\n",
        "  '''\n",
        "  batch_size = img_batch.shape[0]\n",
        "  noise = tf.random.normal([batch_size, noise_dim])\n",
        "\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    # create our fake\n",
        "    generated_image = generator(noise, training=True)\n",
        "\n",
        "    # training using historical images instead\n",
        "    pred_on_real = discriminator(img_batch, training=True)\n",
        "    pred_on_fake = discriminator(generated_image, training=True)\n",
        "\n",
        "    gen_loss = generator_loss(pred_on_fake)\n",
        "    disc_loss = discriminator_loss(pred_on_real, pred_on_fake)\n",
        "  \n",
        "  gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "\n",
        "  gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "  discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "  return gen_loss, disc_loss, generated_image, pred_on_fake\n",
        "\n",
        "\n",
        "def train(images_dataset, epochs, last_epoch):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "    recent_epoch = epoch + last_epoch + 1\n",
        "\n",
        "    data = []\n",
        "\n",
        "    real_imgs = []\n",
        "    time_series_data = []\n",
        "    generated_images = []\n",
        "\n",
        "    batches_finished = 0\n",
        "\n",
        "    print('Start training for epoch {}'.format(recent_epoch))\n",
        "    for img_batch, time_series in images_dataset:\n",
        "      gen_loss, disc_loss, generated_image, pred_on_fake = train_step(img_batch)\n",
        "\n",
        "      # pick random index to sample generated image from batch (as well as associated real img)\n",
        "      r = np.random.randint(img_batch.shape[0])\n",
        "\n",
        "      batches_finished += 1\n",
        "      if (batches_finished % 10) == 0:\n",
        "        data.append((gen_loss.numpy(), disc_loss.numpy(), pred_on_fake.numpy()[r]))\n",
        "        real_imgs.append(img_batch[r])\n",
        "        time_series_data.append(time_series[r])\n",
        "        generated_images.append(generated_image[r])\n",
        "        print('Batch {} training finished'.format(batches_finished))\n",
        "\n",
        "      # need to set manual loop break in current keras version (???)\n",
        "      if batches_finished >= len(images_dataset):\n",
        "        break\n",
        "        \n",
        "    checkpoint.save(checkpoint_dir, options=local_device_option)\n",
        "      \n",
        "    \n",
        "    save_result(data, real_imgs, generated_images, time_series_data, recent_epoch)\n",
        "    display.clear_output(wait=True)\n",
        "    print ('Time for epoch {} is {} sec'.format(recent_epoch, time.time()-start))\n",
        "    print ('generator loss:', gen_loss.numpy())\n",
        "    print ('disciminator loss:', disc_loss.numpy())\n",
        "\n",
        "# NOTE THIS IS THE CORRECT SAVE LOCATION ( THE CHECKPOINTS ARE IN FINALGAN_ONE_2500 THO CARE)\n",
        "def save_result(data, real_imgs, generated_images, time_series_data, epoch_num):\n",
        "  wb = xlsxwriter.Workbook(f'drive/MyDrive/ganstick_project/finalgan_results/epoch{epoch_num:03}.xlsx')\n",
        "  os.makedirs(f'drive/MyDrive/ganstick_project/finalgan_results/epoch{epoch_num:03}/real', exist_ok=True)\n",
        "  os.makedirs(f'drive/MyDrive/ganstick_project/finalgan_results/epoch{epoch_num:03}/generated', exist_ok=True)\n",
        "  os.makedirs(f'drive/MyDrive/ganstick_project/finalgan_results/epoch{epoch_num:03}/timeseriesdata', exist_ok=True)\n",
        "  ws = wb.add_worksheet()\n",
        "  ws.write_row(0, 0, ('Batch Index', 'Generator Loss', 'Discriminator Loss', 'Generated Image Prediction'))\n",
        "  batch_num = 1\n",
        "  for result, real_img, gen_img, timedata in zip(data, real_imgs, generated_images, time_series_data):\n",
        "    ws.write_row(batch_num, 0, (batch_num, result[0], result[1], result[2]))\n",
        "\n",
        "    timedata = timedata.reshape((1,5))\n",
        "    # kinda janky, to get ticker integer encoding\n",
        "    ticker = recover_string_from_int(int(timedata[0][-1]))\n",
        "    first_date = str(timedata[0][1])\n",
        "    last_date = str(timedata[0][2])\n",
        "\n",
        "    df = pd.DataFrame(timedata, columns=['avg_volatility', 'first_date', 'last_date', 'avg_volume', 'ticker'])\n",
        "\n",
        "    # save ticker name as csv name, then timeseries in csv\n",
        "    df.to_csv(f'drive/MyDrive/ganstick_project/finalgan_results/epoch{epoch_num:03}/timeseriesdata/{ticker}_{first_date}_{last_date}.csv', index=False)\n",
        "\n",
        "    save_img = (real_img * 127.5 + 127.5)\n",
        "    save_img = PIL.Image.fromarray(np.uint8(save_img))\n",
        "    save_img.save(f'drive/MyDrive/ganstick_project/finalgan_results/epoch{epoch_num:03}/real/{ticker}_{first_date}_{last_date}.png') \n",
        "\n",
        "    save_img = (gen_img * 127.5 + 127.5)\n",
        "    save_img = PIL.Image.fromarray(np.uint8(save_img))\n",
        "    save_img.save(f'drive/MyDrive/ganstick_project/finalgan_results/epoch{epoch_num:03}/generated/{ticker}_{first_date}_{last_date}.png')\n",
        "\n",
        "\n",
        "\n",
        "    batch_num += 1\n",
        "  wb.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_HRmZJWfRhnX"
      },
      "source": [
        "noise_dim = 100\n",
        "\n",
        "# more is how many more epochs to run\n",
        "# check sasgan_results dir for prev epoch index\n",
        "# saving every epoch\n",
        "\n",
        "MORE_EPOCH = 100\n",
        "FINISHED_EPOCH = 74\n",
        "\n",
        "train(hist_gen, MORE_EPOCH, FINISHED_EPOCH)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}